# FURIA CS Chatbot

Um chatbot interativo com foco total no universo de **Counter-Strike** e, principalmente, na equipe brasileira **FURIA**.  
Criado como projeto web com interface moderna, ele responde a perguntas sobre estratÃ©gias, mapas, tÃ¡ticas, lineups, modos de jogo e tudo que envolve o cenÃ¡rio competitivo de CS â€” com destaque para o time da FURIA.

![DemonstraÃ§Ã£o do projeto](./public/preview/chatbot.jpg)

---

## ğŸš€ Funcionalidades

- ğŸ’¬ Chat com IA que responde sobre Counter-Strike e a equipe FURIA.
- âš¡ Perguntas rÃ¡pidas com sugestÃµes clicÃ¡veis.
- ğŸ§  Conectado a um modelo local via **Ollama** usando **Gemma 2**.
- ğŸ¯ RestriÃ§Ãµes inteligentes: o bot responde **somente sobre CS e FURIA**.
- ğŸ“š Prompts otimizados para glossÃ¡rio, mapas, utilitÃ¡rios, histÃ³ria do time e muito mais.
- ğŸ’¡ Interface rÃ¡pida e responsiva com feedback em tempo real.

---

## ğŸ› ï¸ Tecnologias Utilizadas

- **React + Next.js** â€“ Framework para criaÃ§Ã£o da interface e rotas.
- **TypeScript** â€“ Tipagem estÃ¡tica para maior seguranÃ§a no desenvolvimento.
- **Tailwind CSS** â€“ EstilizaÃ§Ã£o moderna e responsiva.
- **shadcn/ui** â€“ Componentes acessÃ­veis e prontos para uso.
- **Ollama com Gemma 2** â€“ Para rodar o modelo de linguagem localmente.
- **AI SDK da Vercel** â€“ Para facilitar a integraÃ§Ã£o com IA e streaming de resposta.

---

## ğŸ§  ConexÃ£o com IA

Exemplo de cÃ³digo da integraÃ§Ã£o com o modelo de IA via `Ollama`:

```ts
import { createOllama } from 'ollama-ai-provider';
import { streamText } from 'ai';

const ollama = createOllama();

const prompt = "" // Prompt responsÃ¡vel por restringir o modelo a responder apenas sobre CS e FURIA 

export async function POST(request: Request) {
  const { messages } = await request.json();

  const result = await streamText({
    model: ollama('gemma2'),
    system: prompt,
    messages
  });
  return result.toDataStreamResponse();
}
```

## ğŸ§ª Como rodar o projeto localmente

Siga os passos abaixo para rodar o projeto em ambiente local:

1. **Clone o repositÃ³rio:**
```bash
   git clone https://github.com/seu-usuario/furia-cs-chatbot.git
   cd furia-cs-chatbot
```
2. **Instale as dependÃªncias:**
```bash
   npm install
```
3. **Execute o projeto em modo desenvolvimento:**
```bash
   npm run dev
```
4. **InsCertifique-se de que o Ollama estÃ¡ rodando com o modelo gemma2:**
```bash
   ollama run gemma2
```

## ğŸ§‘â€ğŸ’» Autor

Este projeto foi desenvolvido por **GabrielMartinsss** como um experimento educacional e pessoal com foco em IA, NLP e aplicaÃ§Ãµes no universo de e-sports.  
Sinta-se Ã  vontade para explorar, aprender e adaptar.

## ğŸ“„ LicenÃ§a

DistribuÃ­do sob a licenÃ§a MIT.  
Veja o arquivo [`LICENSE`](./LICENSE) para mais detalhes.
