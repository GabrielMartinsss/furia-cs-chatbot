# FURIA CS Chatbot

Um chatbot interativo com foco total no universo de **Counter-Strike** e, principalmente, na equipe brasileira **FURIA**.  
Criado como projeto web com interface moderna, ele responde a perguntas sobre estratÃ©gias, mapas, tÃ¡ticas, lineups, modos de jogo e tudo que envolve o cenÃ¡rio competitivo de CS â€” com destaque para o time da FURIA.

![DemonstraÃ§Ã£o do projeto](./public/preview/chatbot.jpg)

---

## ğŸš€ Funcionalidades

- ğŸ’¬ Chat com IA que responde sobre Counter-Strike e a equipe FURIA.
- âš¡ Perguntas rÃ¡pidas com sugestÃµes clicÃ¡veis.
- ğŸ§  Conectado a um modelo local via **Ollama** usando **Gemma 2**.
- ğŸ¯ RestriÃ§Ãµes inteligentes: o bot responde **somente sobre CS e FURIA**.
- ğŸ“š Prompts otimizados para glossÃ¡rio, mapas, utilitÃ¡rios, histÃ³ria do time e muito mais.
- ğŸ’¡ Interface rÃ¡pida e responsiva com feedback em tempo real.

---

## ğŸ› ï¸ Tecnologias Utilizadas

- **React + Next.js** â€“ Framework para criaÃ§Ã£o da interface e rotas.
- **TypeScript** â€“ Tipagem estÃ¡tica para maior seguranÃ§a no desenvolvimento.
- **Tailwind CSS** â€“ EstilizaÃ§Ã£o moderna e responsiva.
- **shadcn/ui** â€“ Componentes acessÃ­veis e prontos para uso.
- **Ollama com Gemma 2** â€“ Para rodar o modelo de linguagem localmente.
- **AI SDK da Vercel** â€“ Para facilitar a integraÃ§Ã£o com IA e streaming de resposta.

---

## ğŸ§  ConexÃ£o com IA

Exemplo de cÃ³digo da integraÃ§Ã£o com o modelo de IA via `Ollama`:

```ts
import { createOllama } from 'ollama-ai-provider';
import { streamText } from 'ai';

const ollama = createOllama();

const prompt = "" // Prompt responsÃ¡vel por restringir o modelo a responder apenas sobre CS e FURIA 

export async function POST(request: Request) {
  const { messages } = await request.json();

  const result = await streamText({
    model: ollama('gemma2'),
    system: prompt,
    messages
  });
  return result.toDataStreamResponse();
}
```

---

## ğŸ“£ Aviso Importante sobre o Modelo de IA

**AtenÃ§Ã£o:** O modelo de IA utilizado neste projeto atualmente Ã© o **Gemma2**, atravÃ©s do **Ollama**. No entanto, como o modelo pode estar desatualizado, hÃ¡ a possibilidade de ele nÃ£o fornecer respostas precisas ou completamente atualizadas, especialmente sobre tÃ³picos recentes.

Para obter resultados mais precisos e atualizados, recomenda-se substituir o uso do **Ollama** por **OpenAI** (como o modelo GPT-4 ou GPT-3.5), que sÃ£o mais avanÃ§ados e frequentemente atualizados.

Para realizar essa mudanÃ§a, basta ajustar a integraÃ§Ã£o com o modelo na configuraÃ§Ã£o do projeto para usar a API da OpenAI.

#### Exemplo de cÃ³digo da integraÃ§Ã£o com o modelo de IA com `OpenAI`:

```ts
import { Configuration, OpenAIApi } from 'openai-edge';
import { OpenAIStream, StreamingTextResponse } from 'ai';

const config = new Configuration({
  apiKey: process.env.OPENAI_API_KEY // Chave da OpenAI
})
const openai = new OpenAIApi(config);
export const runtime = 'edge';

export async function POST(request: Request) {
  const { message } = request.json();

  const response = await openai.createChatCompletion({
    model: 'gpt-3.5-turbo', // versÃ£o do modelo
    stream: true;
    message
  })
  const stream = OpenAIStream(response);

  return new StreamingTextResponse(stream);
}
```
#### âš ï¸ lembrete
 - Ao utilizar a OpenAI a dependÃªncia necessÃ¡ria sera `openai-edge` ao invÃ©s de `ollama-ai-provider`

 - OpenAI nÃ£o Ã© gratuita. 

---

## ğŸ§ª Como rodar o projeto localmente

Siga os passos abaixo para rodar o projeto em ambiente local:

1. **Clone o repositÃ³rio:**
```bash
   git clone https://github.com/seu-usuario/furia-cs-chatbot.git
   cd furia-cs-chatbot
```
2. **Instale as dependÃªncias:**
```bash
   npm install
```
3. **Execute o projeto em modo desenvolvimento:**
```bash
   npm run dev
```
4. **InsCertifique-se de que o Ollama estÃ¡ rodando com o modelo gemma2:**
```bash
   ollama run gemma2
```

## ğŸ§‘â€ğŸ’» Autor

Este projeto foi desenvolvido por **GabrielMartinsss** como um experimento educacional e pessoal com foco em IA, NLP e aplicaÃ§Ãµes no universo de e-sports.  
Sinta-se Ã  vontade para explorar, aprender e adaptar.

## ğŸ“„ LicenÃ§a

DistribuÃ­do sob a licenÃ§a MIT.  
Veja o arquivo [`LICENSE`](./LICENSE) para mais detalhes.
